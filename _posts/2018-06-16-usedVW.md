---
layout: post
title: "Modeling used VW Golf car prices with GLM"
author: Maarten
date: 2018-06-15
categories: data_science
tags: ML glmnet
image: /img/usedVW_files/figure-markdown_github/glmnet-1.png
---


What is the right price for a second hand car? Which offers are under priced and wich overpriced? It is difficult/impossible to figure that out on the spot at a dealership, or even online. In this example I try to establish the fair asking price for a used VW Golf. How this price is affected by model, age, miles etc. might influence the buying decision. Maybe this will turn into an exercise of reverse engineering the pricing model used by used car salesmen but that should be interesting nonetheless.

### Get data

Data was downloaded from buyacar.co.uk where around 1400+ VW Golf used or nearly new cars were on offer. Most data wrangling was done outside this project.

``` r
library(caret) 
library(tidyverse)

usedvw <- read.csv("vwgolfusedcar.csv")[-c(1,3)]
usedvw %>% filter(status!="New", !is.na(engine), !is.na(edition), !is.na(trim)) %>%
  mutate(price=as.numeric(price), engine=as.factor(engine), fuel=as.factor(fuel)) -> usedvw

summary(usedvw)
```

    ##         status        price              gear         color    
    ##  Nearly New:641   Min.   : 7499   automatic:424   Black  :292  
    ##  New       :  0   1st Qu.:13492   manual   :791   White  :280  
    ##  Used      :574   Median :17290                   Grey   :179  
    ##                   Mean   :17437                   Silver :176  
    ##                   3rd Qu.:20000                   Blue   :136  
    ##                   Max.   :34788                   Red    :120  
    ##                                                   (Other): 32  
    ##       year            fuel         miles       engine         edition    
    ##  Min.   :2013   Diesel  :644   Min.   :  453   1  : 27   estate   : 115  
    ##  1st Qu.:2015   Electric:  0   1st Qu.: 5526   1.2: 27   hatchback:1100  
    ##  Median :2017   Hybrid  : 57   Median :12966   1.4:291                   
    ##  Mean   :2016   Petrol  :514   Mean   :16092   1.5: 27                   
    ##  3rd Qu.:2017                  3rd Qu.:23466   1.6:318                   
    ##  Max.   :2018                  Max.   :66563   2  :525                   
    ##                                                                          
    ##       trim    
    ##  SE     :286  
    ##  MATCH  :203  
    ##  GTD    :202  
    ##  GT     :159  
    ##  GTI    :101  
    ##  R      : 79  
    ##  (Other):185

### Exploratory plots

Use the featureplots function in caret to explore the available covariates. Look for outliers and other peculiarities in the data.

``` r
library(gridExtra)
grid.arrange(qplot(x=gear, y=price, data=usedvw, geom="point", color=fuel),
             qplot(x=year, y=price, data=usedvw, geom="point", color=gear),
             qplot(x=miles, y=price, data=usedvw, geom="point", color=trim),nrow=3)
```

![](/img/usedVW_files/figure-markdown_github/explore-1.png)

### Partition data

To calculate a certain model, optimize the model and estimate how well the model is predicting outcome we can split the data set in 3 parts: a training, cv and test set. A training set is used to train de model on the available data. The cv set is used to optimize the parameters in the model. The test set is used for estimating model performance.

A training and test set are definitely necessary, a cv set does not have to be generated when other methods of cross validation are applied, e.g. leave one out cv or k-fold cv or repeated k-fold cv. The repeated cv methods are useful when the number of samples(examples) is on the low side (~ &lt;1000 (?)). In the case of the current used VW data (m=574) it is useful to do a repeated cross validation.

Dataset is split on the outcome variable. In the current example that is price.

``` r
set.seed(123)

split_train <- createDataPartition(y=usedvw$price, p=0.8, list=F)
training <- usedvw[split_train,]
test <- usedvw[-split_train,]
```

### GLM modelling of the data

Train a generalized linear regression model. Apply regularisation in the form of ridge, lasso or both (elastic net) by varying the alpha parameter. Also tune the model for the penalty parameter lambda.

Use repeated k-fold cross validation to estimate model performance.

``` r
library(glmnet)

# apply a repeated k-fold cross validation
control <- trainControl( ## 10 fold CV
                            method="repeatedcv", 
                            number=10, 
                            repeats=3)

# train the model with tuning of alpha (ratio between ridge and lasso) and lambda (penalty factor)
glmnetGrid <-  expand.grid(alpha = seq(0.3,1,0.1), 
                           #alpha = 1,                 #for simplicity keep alpha at 1
                           lambda = seq(2,20,0.25) )

#avoid data leakage and apply center and scale variables in the train process
#remove variables with zero or near zero variance in train process

model <- train(price ~ . , data = training , 
               method = "glmnet",
               family = "gaussian",
               trControl = control,
               tuneGrid = glmnetGrid,
               preProc = c("center", "scale","nzv")
               )

model$bestTune
```

    ##     alpha lambda
    ## 140   0.4   18.5

``` r
# plot model performance metric against tuning parameters
ggplot(model)
```

    ## Warning: The shape palette can deal with a maximum of 6 discrete values
    ## because more than 6 becomes difficult to discriminate; you have 8.
    ## Consider specifying shapes manually if you must have them.

    ## Warning: Removed 146 rows containing missing values (geom_point).

![](/img/usedVW_files/figure-markdown_github/glmnet-1.png)

``` r
model$bestTune
```

    ##     alpha lambda
    ## 140   0.4   18.5

``` r
# here we look at estimated feature importance
importance <- varImp(model, scale=FALSE)
plot(importance)
```

![](/img/usedVW_files/figure-markdown_github/glmnet-2.png)

``` r
predictors(model)
```

    ##  [1] "statusUsed"       "gearmanual"       "colorBlue"       
    ##  [4] "colorGrey"        "colorRed"         "colorSilver"     
    ##  [7] "colorWhite"       "year"             "fuelPetrol"      
    ## [10] "miles"            "engine1.4"        "editionhatchback"
    ## [13] "trimGT"           "trimGTD"          "trimGTI"         
    ## [16] "trimMATCH"        "trimR"            "trimS"           
    ## [19] "trimSE"

``` r
# best model is selected as having lowest RMSE (default, could be changed)
# looking at residuals and predicted vs actual values is possible
grid.arrange(qplot(x=training$price, y=resid(model)),
             qplot(x=training$price, y=predict(model, training)), ncol=2)
```

![](/img/usedVW_files/figure-markdown_github/glmnet-3.png)

The model fit seems to be sub optimal as residuals show a pattern instead of a random distribution. Looking into feature engineering and/or alternative learning methods could improve the fit and model performance.

### Prediction

Given the GLM model, predict the used VW car price in the test set and calculate prediction accuracy.

``` r
# predict test values and calculate prediction performance

postResample(pred=predict(model, newdata = training), obs=training$price)
```

    ##         RMSE     Rsquared          MAE 
    ## 1633.6087961    0.8933214 1228.5229677

``` r
postResample(pred=predict(model, newdata = test), obs=test$price)
```

    ##         RMSE     Rsquared          MAE 
    ## 1547.7520769    0.9039202 1210.9008192

``` r
grid.arrange(qplot(x=training$price, y=predict(model, training), color=training$trim),
             qplot(x=test$price, y=predict(model, test), color=test$trim),ncol=2)
```

![](/img/usedVW_files/figure-markdown_github/predict-1.png)

### Final remarks

The glm model predicts test data outcome with similar RMSE and MAE as the training data showing that the model training and tuning resulted in a model that does not overfit.

Tuning parameter alpha showed no large effect on the model performance and could be set at 1 for simplicity. At alpha=1 only lasso regularisation occurs and only contributing features are included in the model (in model feature selection).

Regularisation of the features by tuning lambda results in a balanced model.

The R squared values indicate that the performance of this linear regression model is okay but can probably be improved upon by other ML methods.
