---
layout: post
title: "Running fitness trend analysis: EF efficiency factor"
author: Maarten
date: 2018-02-07
categories: performance
tags: EF triathlon Golden_Cheetah coaching
image: /img/runEF_GC2_files/figure-markdown_github/unnamed-chunk-2-1.png
---

A potentially useful measure for monitoring running fitness development over time is the Efficiency Factor (EF, Friel et al). For a single workout the EF is calculated as average run speed over average heart rate. For a series of comparable running workouts the EF over time shows increasing or decreasing running fitness. EF evaluates if running speed increases for the same HR, if similar run speeds are reached easier with a lower HR, or a combination of both of course.

TrainingPeaks or Garmin Connect do not offer the option of trend views of EF. Also running EF is not available (yet) in *GoldenCheetah* open source analysis software. However GC offers a webserver functionality which can be used to extract workout metrics which can be used to calculate EF into R.

------------------------------------------------------------------------

### Extract metrics data from GC

Use GoldenCheetah webserver to query either individual workouts or workout summary metrics which have already been loaded into GC.

Prerequisites are:

-   to have the GC webserver running (on command line from GC application folder: ./GoldenCheetah --server)
-   have up to date workout data uploaded into GC

In R, using the RCurl library, the GC webserver can now be queried using a constructed url. From localhost with standard port number 12021 and with athlete name all metrics and metadata can be queried for all available workouts or within a certain time period. More info in <https://github.com/GoldenCheetah/GoldenCheetah/wiki/UG_Special-Topics_REST-API-documentation>

### Get data

Start GoldenCheetah server

``` r
system2(paste0(gcdirectory, "GoldenCheetah"), "--server", wait=FALSE)
```

Load libraries

``` r
library(RCurl);library(ggplot2);library(dplyr);library(lubridate)
```

Construct url and apply data extraction

``` r
athlete <- "Maarten"
url.selection <- paste("http://localhost:12021/", athlete, "?metadata=Sport", 
			"&format=csv", sep="")
data.all <- read.csv(text=getURL(url.selection))
```

Summary of workouts available

``` r
summary(data.all$Sport)
```

    ##      Bike  Run Swim 
    ##    5  144  149   30

Select all runs, format data. Also

-   calculate EF: 1000/xPace / Average HR (units are meters/minute /bpm -&gt; meters/heartbeat)

-   define a metric to identify interval workouts. An EF trend is preferably done on aerobic similar endurance type workouts. The idea here is that peak pace over a longer period should not be much different from a short period peak pace: 20min vs 1min peak pace

``` r
runs <- data.all[data.all$Sport == "Run",]

runs <- runs %>% mutate(date=as_date(date)) %>%         #formate date column
  filter(Average_Heart_Rate > 40) %>%                   #remove workouts without HR data
  mutate(Duration = Duration/60) %>%                    #convert to minutes
  filter(Duration > 25 & Duration < 200) %>%            #remove workouts between 25-200min
  filter(X20_min_Peak_Pace > 0 ) %>%                    #remove workouts without 20min peak
  filter(X1_min_Peak_Pace > 0 ) %>%                     #remove workouts without 1min peak
  mutate(EF=1000/(xPace*Average_Heart_Rate)) %>%        #create Efficiency factor column
  mutate(Interval=X20_min_Peak_Pace/X1_min_Peak_Pace)   #create expected interval metric
```

    ## Warning in strptime(xx, f <- "%Y-%m-%d", tz = "GMT"): unknown timezone
    ## 'zone/tz/2017c.1.0/zoneinfo/Europe/London'

### Explore data

See how many runs there are and which could be identified as potential intervals

``` r
qplot(x=date, y=Duration, data=runs)
```

![](/img/runEF_GC2_files/figure-markdown_github/explore_data-1.png)

``` r
qplot(x=date, y=Interval, data=runs, color=EF)
```

![](/img/runEF_GC2_files/figure-markdown_github/explore_data-2.png)

After cross checking with the actual workout metadata it seems that interval workouts are mostly identified with an expected interval metric &gt; 1.3

See what effect an interval workout has on EF

``` r
qplot(x=date, y=EF, data=runs, color=Interval>1.3)
```

![](/img/runEF_GC2_files/figure-markdown_github/unnamed-chunk-1-1.png)

Now we can look at the EF over time for all endurance running workouts

``` r
c <- ggplot(runs[(runs$Interval<1.3 & runs$Interval>1), ], 
            aes(y=EF, x=date, colour=Duration)) +
            ggtitle("Run EF plot") + ylab("Efficiency Factor")
c + stat_smooth(method=lm, formula=y~poly(x,9)) + geom_point()  
```

![](/img/runEF_GC2_files/figure-markdown_github/unnamed-chunk-2-1.png)

And look at EF for the 2018 season.

``` r
c <- ggplot(runs[(runs$Interval<1.3 & runs$Interval>1 & runs$date > "2017-11-01"), ], 
            aes(y=EF, x=date, colour=Duration)) +
            ggtitle("Run EF plot 2018 season") + ylab("Efficiency Factor")
c + stat_smooth(method=loess) + geom_point()  
```

![](/img/runEF_GC2_files/figure-markdown_github/unnamed-chunk-3-1.png)

### Conclusion

Data extraction via GoldenCheetah server works great. A large number of metrics can be extracted for each workout. Some metrics are sport specific, some are general metrics. Metadata is a bit sparse and probably depends a lot on manual annotation within GC.

In terms of this specific data example, a clear improvement of EF is present during training periods (with endurance as well as interval training) when base fitness is low (period of little run training). When run training is reduced significantly then EF decreases accordingly.

A plateau is reached during 2017 race season when focus is more on maintaining present fitness and prepare for races.

------------------------------------------------------------------------

``` r
system2("osascript", "-e 'quit app \"GoldenCheetah\"'", wait=FALSE)
```
